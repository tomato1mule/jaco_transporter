{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "C,H,W = 3, 320, 480\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t2i(o):\n",
    "    o = o.detach().cpu()\n",
    "    o = o.permute(1,2,0)\n",
    "    return Image.fromarray(np.array(o).astype(np.uint8))\n",
    "\n",
    "def drawCircle(img, r, coord,color='blue'):\n",
    "    img = img.copy()\n",
    "    h, w = coord\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw.ellipse((w-r, h-r, w+r, h+r), fill = color)\n",
    "    return img\n",
    "\n",
    "def drawRect(img, size, coord, color='blue'):\n",
    "    img = img.copy()\n",
    "    h, w = coord\n",
    "    Lh, Lw = size\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw.rectangle((w-(Lw/2), h-(Lh/2), w+(Lw/2), h+(Lh/2)), fill = color)\n",
    "    return img\n",
    "\n",
    "def drawCircle(img, D, coord, color='blue'):\n",
    "    r = D/2\n",
    "    img = img.copy()\n",
    "    h, w = coord\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw.ellipse((w-r, h-r, w+r, h+r), fill = color)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_world(obj, goal):\n",
    "    objL = 50\n",
    "    goalL = 70\n",
    "    o = torch.zeros(C, H, W)\n",
    "    img = t2i(o)\n",
    "    img = drawRect(img, (goalL,goalL), (goal[0],goal[1]), 'green')\n",
    "    img = drawCircle(img, objL, (obj[0],obj[1]), 'red')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/hw/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "#https://pytorch.org/hub/pytorch_vision_fcn_resnet101/\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet50', pretrained=False)\n",
    "model.classifier[4] = torch.nn.Conv2d(512, 1, kernel_size = (1,1), stride = (1,1))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "\n",
    "# Optimizer\n",
    "params = model.parameters()\n",
    "\n",
    "optimizer = torch.optim.Adam(params, \n",
    "                             lr=lr,\n",
    "                             betas=(0.9, 0.98),\n",
    "                             eps=1e-09, \n",
    "                             weight_decay=1e-4, \n",
    "                             amsgrad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_demos = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "demos = []\n",
    "\n",
    "for _ in range(n_demos):\n",
    "    offset = 0.1\n",
    "    \n",
    "    obj = (torch.rand(2) * (1 - 2*offset) + offset) * torch.tensor([H,W])\n",
    "    #goal = (torch.rand(2) * (1 - 2*offset) + offset) * torch.tensor([H,W])\n",
    "    goal = torch.tensor([0.8, 0.8]) * torch.tensor([H,W])\n",
    "    img = draw_world(obj, goal)\n",
    "    \n",
    "    demos.append({'img':img, \n",
    "                  'o':preprocess(img),\n",
    "                  'obj':obj,\n",
    "                  'goal':goal})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAFACAIAAADrqjgsAAADfElEQVR4nO3d0UqbQRRGUVP64Hlze1EoBYVoyD+z57jWtegBYedjLvTtDQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPluuw8AFnl/9AVyUOM3AsM97PJHuhDhFwEzPdHljwRir1+7DwBe7yV1fuH34Tk+IGGUi5KqFFtY0DDHdYPXlN7C5yJMsCygkrGSBQ3HWzlvTemVBBrOtr6YGr2MQANECTQcbNeYNaLXEGg41d5KavQCAg0QJdBwpMKALdwwm0DDeTpl7FwykkADRAk0QJRAw2Fqrwq1eyYRaIAogQaIEmg4SfM9oXnVAAINECXQAFG/dx8AjHDffcBD990HfJ8FDRAl0ABRAg0QJdAAUQINECXQAFECDRAl0HCS2+4DPnW7775gKIEGiBJogCiBhsPUXjm8b1xHoAGiBBogSqDhPJ1XDu8blxJoOFKh0ep8NYEGiBJoONXeEW0+LyDQcLBdjVbnNQQaIEqg4WzrR7T5vIxAw/FWNlqdV/JfvWGCv41+v/RH3K/87nzGgoY5rpvS6ryFBQ2jvHxKS/NGFjQM9Koprc57WdAw079GP7GmdTlCoGG4r5e68Pc9+J9Aw0+hv8fxBg0QJdAAUQINECXQAFECDRAl0ABRAg0QJdAAUQINECXQAFECDRAl0ABRAg0QJdAAUQINECXQAFECDRAl0ABRAg0QJdAAUQINECXQAFECDRAl0ABRAg0QJdAAUQINECXQAFECDRAl0ABRAg0QJdAAUQINECXQAFECDRAl0ABRAg0QJdAAUQINECXQAFECDRAl0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/2B+lbyVJHpUGrAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=480x320 at 0x7FDAC94E61F0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demos[0]['img']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Os = []\n",
    "targets = []\n",
    "\n",
    "for demo in demos:\n",
    "    Os.append(demo['o'])\n",
    "    targets.append(demo['obj'].type(torch.int64))\n",
    "    \n",
    "Os = torch.stack(Os,axis=0).to(device)\n",
    "targets = torch.stack(targets,axis=0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = model(Os)['out'].squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = F.log_softmax(t.view(t.shape[0],-1),dim=-1).reshape(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vh = V.gather(dim=1, index=targets[:,0].unsqueeze(-1).unsqueeze(-1).expand(-1,1,W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_targets = Vh.squeeze(1).gather(dim=1, index=targets[:,1].unsqueeze(-1).type(torch.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = (-1 * V_targets.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tests = 5\n",
    "\n",
    "test_demos = []\n",
    "\n",
    "for _ in range(n_tests):\n",
    "    offset = 0.1\n",
    "    \n",
    "    obj = (torch.rand(2) * (1 - 2*offset) + offset) * torch.tensor([H,W])\n",
    "    #goal = (torch.rand(2) * (1 - 2*offset) + offset) * torch.tensor([H,W])\n",
    "    goal = torch.tensor([0.8, 0.8]) * torch.tensor([H,W])\n",
    "    img = draw_world(obj, goal)\n",
    "    \n",
    "    test_demos.append({'img':img, \n",
    "                  'o':preprocess(img),\n",
    "                  'obj':obj,\n",
    "                  'goal':goal})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_test = []\n",
    "gt = []\n",
    "\n",
    "for demo in test_demos:\n",
    "    o_test.append(demo['o'])\n",
    "    gt.append(demo['obj'].type(torch.int64))\n",
    "    \n",
    "o_test = torch.stack(o_test,axis=0).to(device)\n",
    "gt = torch.stack(gt,axis=0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    t_test = model(o_test)['out'].squeeze(1)\n",
    "    V = F.softmax(t_test.view(t_test.shape[0],-1),dim=-1).reshape(t_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAFACAIAAADrqjgsAAADUklEQVR4nO3YwW7CMBBFUVLx4fw5XbAsaho8tl/tc9YhjBT5auTbDQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOjlmDwDkecweoIfH7AGu+5o9AADvCTRAKIEGCCXQAKEEGiCUQAOEEmiAUAINEEqgAUIJNEAogQYIJdAAoQQaIJRAA4QSaIBQAg0QSqABQgk0QCiBBggl0AChBBoglEADhBJogFACDRDqPnuAfT3PHjhGTAHkEujRTrv880mlhj0J9CB/7/Ivv1Vq2Io76BFa6tzjPcC/YIPuqzyprxdapWEHNuiO+i28VmnYgQ26iwEBtUrD8mzQ9Uaut1ZpWJhAFxtfTI2GVQk0QCiBrjRrmbVEw5IEuszcSmo0rEegAUIJdI2EBTZhBqCQQBfIKWPOJEA7gQYIJdAAoQS6VdqtQto8wMcEGiCUQAOEEugmmfcJmVMBVwk0QCiBBggl0AChBBoglEADhBJogFACDRBKoAFCCTRAKIEGCCXQTY7ZA7yVORVwlUADhBJogFAC3SrtPiFtHuBjAg0QSqABQgl0gZxbhZxJgHYCXSOhjAkzAIUEGiCUQJeZu8Ban2E9Al1pViXVGZYk0AChBLrY+GXW+gyrEuh6I4upzrCw++wB1vTq5rP/XwALc8z76tRonw124KSPUJhpHwz24Q56hKqqqjNsxZEf7YNt2keCPTn705yW2rcBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABm+AZq+SObhA/gBgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=480x320 at 0x7FDA070CEB20>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_idx = 4\n",
    "plt.imshow(V[test_idx].detach().numpy())\n",
    "plt.show()\n",
    "test_demos[test_idx]['img']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
